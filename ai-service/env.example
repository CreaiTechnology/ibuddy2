# AI Service Environment Variables

# Server Configuration
PORT=3002
NODE_ENV=development

# Authentication
JWT_SECRET=change-this-to-a-secure-key

# AI Configuration
GEMINI_API_KEY=your-gemini-api-key
OPENAI_API_KEY=your-openai-api-key
OPENROUTER_API_KEY=your-openrouter-api-key
ENABLE_MODEL_FALLBACK=true
DEFAULT_AI_MODEL=gemini-2.0-flash-lite
# Available models: gemini-2.0-flash-lite, gemini-1.5-pro-latest, gpt-4o-mini

# Model Selection Configuration
ENABLE_AUTO_MODEL_SELECTION=true
COMPLEXITY_THRESHOLD_MEDIUM=100
COMPLEXITY_THRESHOLD_HIGH=200

# Context Processing
SHORT_TERM_WINDOW_SIZE=5
MID_TERM_WINDOW_SIZE=15
LONG_TERM_WINDOW_SIZE=50
ENABLE_CONTEXT_COMPRESSION=true
COMPRESSION_THRESHOLD=10
COMPRESSION_TARGET=5

# Intent Recognition
INTENT_CONFIDENCE_THRESHOLD=0.7
INTENT_CONTEXT_BOOST=true
INTENT_MAX_CACHE_AGE=3600

# Message Queue
ENABLE_MESSAGE_QUEUE=false
RABBITMQ_URL=amqp://localhost:5672
RABBITMQ_QUEUE_NAME=ai-service-queue

# Redis Cache
ENABLE_REDIS_CACHE=false
REDIS_URL=redis://localhost:6379

# Database - Used for context storage
# If not provided, context will be stored in memory (not recommended for production)
SUPABASE_URL=your-supabase-url
SUPABASE_SERVICE_KEY=your-supabase-service-key

# Logging
LOG_LEVEL=info

# Timeout settings (in milliseconds)
AI_REQUEST_TIMEOUT=15000 
CONTEXT_REQUEST_TIMEOUT=5000

# Performance
MAX_TOKENS_PER_REQUEST=2048
CONTEXT_WINDOW_SIZE=10 # How many previous messages to include in context (legacy setting)
RATE_LIMIT_MAX=100 # Max requests per window
RATE_LIMIT_WINDOW_MS=60000 # Window size in milliseconds (1 minute) 